---
title: "DPS Assignemnt1"
output:
  html_document:
    df_print: paged
---

Importing cs files from document


```{r}
#install.packages("dplyr")
#install.packages(c("ggplot2", "ggpubr", "tidyverse", "broom", "AICcmodavg"))

library(dplyr)
#library(ggpubr)
#library(tidyverse)
#library(broom)
#library(AICcmodavg)
library(ggplot2)
library(stats)

```

we sent 0 for article setting and 1 for new settings
```{r}


hibench_Kmean_6nodes_article_settings <- read.csv("../experiments/hibench_5workers1master_original.report", sep="")
hibench_Kmean_6nodes_new_settings <- read.csv("../experiments/hibench_5workers1master.report", sep="")

hibench_Kmean_6nodes_article_settings["node_numb"] <- "5"
hibench_Kmean_6nodes_article_settings["settings"]<- "0"

hibench_Kmean_6nodes_new_settings["node_numb"] <- "5"
hibench_Kmean_6nodes_new_settings["settings"]<- "1" 


hibench_Kmean_11nodes_article_settings <- read.csv("../experiments/hibench_10workers1master_original.report", sep="")
hibench_Kmean_11nodes_new_settings <- read.csv("../experiments/hibench_10workers1master.report", sep="")


hibench_Kmean_11nodes_new_settings["node_numb"] <- "10"
hibench_Kmean_11nodes_new_settings["settings"]<- "1"

hibench_Kmean_11nodes_article_settings["node_numb"] <- "10"
hibench_Kmean_11nodes_article_settings["settings"] <- "0"



hibench_Kmeans_15nodes_article_settings <- read.csv("../experiments/hibench_15workers1master_original.report", sep="")
hibench_Kmeans_15nodes_new_settings <- read.csv("../experiments/hibench_15workers1master.report", sep="")

hibench_Kmeans_15nodes_new_settings["node_numb"] <- "15"
hibench_Kmeans_15nodes_new_settings["settings"]<- "1"

hibench_Kmeans_15nodes_article_settings["node_numb"] <- "15"
hibench_Kmeans_15nodes_article_settings["settings"] <- "0"


```

we sent 0 for article setting and 1 for new settings
```{r}


hibench_Wordcount_small_article_settings <- read.csv("../experiments/hibench_wordcount_14workers_1master_original_small.report", sep="")
hibench_Wordcount_small_new_settings <- read.csv("../experiments/hibench_wordcount_14workers_1master_small_new.report", sep="")

hibench_Wordcount_small_article_settings["dataset"] <- "0.32GB"
hibench_Wordcount_small_article_settings["settings"]<- "0"

hibench_Wordcount_small_new_settings["dataset"] <- "0.32GB"
hibench_Wordcount_small_new_settings["settings"]<- "1" 


hibench_Wordcount_large_article_settings <- read.csv("../experiments/hibench_wordcount_14workers_1master_original_large.report", sep="")
hibench_Wordcount_large_new_settings <- read.csv("../experiments/hibench_wordcount_14workers_1master_new_large.report", sep="")

hibench_Wordcount_large_article_settings["dataset"] <- "3.2GB"
hibench_Wordcount_large_article_settings["settings"]<- "0"

hibench_Wordcount_large_new_settings["dataset"] <- "3.2GB"
hibench_Wordcount_large_new_settings["settings"]<- "1" 

hibench_Wordcount_huge_article_settings <- read.csv("../experiments/hibench_wordcount_14workers_1master_original_huge.report", sep="")
hibench_Wordcount_huge_new_settings <- read.csv("../experiments/hibench_wordcount_14workers_1master_new_huge.report", sep="")

hibench_Wordcount_huge_article_settings["dataset"] <- "32GB"
hibench_Wordcount_huge_article_settings["settings"]<- "0"

hibench_Wordcount_huge_new_settings["dataset"] <- "32GB"
hibench_Wordcount_huge_new_settings["settings"]<- "1" 

```


Summary statistics are located at the end of the file

joining dfs together
```{r}

df_article_settings = rbind(hibench_Kmean_11nodes_article_settings, hibench_Kmean_6nodes_article_settings, hibench_Kmeans_15nodes_article_settings)
df_new_setting = rbind(hibench_Kmean_11nodes_new_settings, hibench_Kmean_6nodes_new_settings, hibench_Kmeans_15nodes_new_settings)


df_article_settings_box = df_article_settings
df_new_settings_box = df_new_setting

df_article_settings_bar = df_article_settings
df_new_settings_bar = df_new_setting



df_article_settings_e2 = rbind(hibench_Wordcount_large_article_settings, hibench_Wordcount_small_article_settings, hibench_Wordcount_huge_article_settings)
df_new_setting_e2 = rbind(hibench_Wordcount_large_new_settings, hibench_Wordcount_small_new_settings, hibench_Wordcount_huge_new_settings)


df_article_settings_box_e2 = df_article_settings_e2
df_new_settings_box_e2 = df_new_setting_e2

df_article_settings_bar_e2 = df_article_settings_e2
df_new_settings_bar_e2 = df_new_setting_e2


df_stat_test_e2 = rbind(df_article_settings_bar_e2, df_new_settings_bar_e2)


```

now create 2 box plots - for Experment 1

```{r}
article_setting_box <- ggplot(df_article_settings_box, aes(x = node_numb, y = Duration.s., fill= Type)) +
  geom_boxplot() + xlab("Number of Nodes") + ylab("Duration (seconds)") + scale_x_discrete(limits=c("5","10","15")) #+ expand_limits(x = 0, y = 0)# + ggtitle("K-means performace with Article Settings") 

article_setting_box 


new_setting_box <- ggplot(df_new_settings_box, aes(x = node_numb, y =Duration.s., fill= Type)) +
  geom_boxplot()   + xlab("Number of Nodes") + ylab("Duration (seconds)") + scale_x_discrete(limits=c("5","10","15")) #+ expand_limits(x = 0, y = 0) #+ ggtitle("K-means performace with Our Settings")

new_setting_box 
 
```

2 box plot for experment 2 

```{r}
article_setting_box <- ggplot(df_article_settings_box_e2, aes(x = dataset, y = Duration.s.)) +
  geom_boxplot() + xlab("Size of dataset") + ylab("Duration (seconds)") + scale_x_discrete(limits=c("0.32GB","3.2GB","32GB")) #+ expand_limits(x = 0, y = 0)# + ggtitle("Word count performance with Article Settings") 


article_setting_box
 
new_setting_box <- ggplot(df_new_settings_box_e2, aes(x = dataset, y =Duration.s.)) +
  geom_boxplot()   + xlab("Size of dataset") + ylab("Duration (seconds)") + scale_x_discrete(limits=c("0.32GB","3.2GB","32GB")) #+ expand_limits(x = 0, y = 0)#+ ggtitle("Word count performace with Our Settings")

new_setting_box 

```
Since i dont want to go to bottom of page I dont to see if duration is stat diff in gb size 
```{r}


two.anova_GBdiff = aov(Duration.s. ~ dataset + settings, data=df_stat_test_e2)


summary(two.anova_GBdiff)


TukeyHSD(two.anova_GBdiff)


```



bar plot
```{r}


df_bar = rbind(df_article_settings_bar, df_new_settings_bar)
df_bar["comb_settings"] <- paste(df_bar$Type , df_bar$settings)




article_setting_bar <- ggplot(df_bar, aes(x = node_numb, y=Duration.s., fill = comb_settings)) + geom_bar(stat="identity" , position='dodge') +
  ggtitle("K-means performace ") + ylab("Duration (seconds)") + scale_x_discrete(limits=c("5","10","15"), name="Number of Nodes") +
  scale_fill_discrete(name="System, settings", labels = c("Hadoop, Article", "Hadoop , Our", "Spark , Article", "Spark , Our"))
  



article_setting_bar 





```

okay now need a ANOVA 
H0: The means are equal for varables
H1: The means are different 

```{r}

df_stat = df_bar



df_stat["comb_settings_nodes"] = paste(df_stat$Type, df_stat$settings ,df_stat$node_numb)

df_stat_test <- data.frame( df_stat$Duration.s.,  df_stat$comb_settings_nodes)
colnames(df_stat_test) <- c("Duration.s." , "comb_settings_nodes" )

one.way <- aov(Duration.s. ~ comb_settings_nodes, data = df_stat_test)

print("duration for combo stat of combo setting nodes")



summary(one.way)


```
So we find statistically significant difference between our treament set of setting, nodes, and System. We would now like to know is there a statically different results in our setting from the authors

H0 : The means are equal for both variables 
H1 ; the means are different for both variables 

```{r}
df_stat2 = df_bar

df_stat2["comb_nodes"] = paste(df_stat$Type , df_stat$node_numb)

df_stat_test <- data.frame( df_stat2$Duration.s.,  df_stat2$comb_nodes , df_stat2$settings, df_stat2$node_numb, df_stat2$Type)
colnames(df_stat_test) <- c("Duration.s." , "comb_nodes" ,"settings", "node_numb", "system_type")
```


We see out setting are not statically signfication when we hold system type and node numb content at a .001 level. we do see 

```{r}
one.way_nodenumber <- aov(Duration.s. ~ node_numb * system_type, data = df_stat_test)

print("does the mean different with node number")
summary(one.way_nodenumber)

TukeyHSD(one.way_nodenumber)

```
We want to see if our setting matter 
```{r}

one.way_settings <- aov(Duration.s. ~ settings + ( system_type + node_numb), data = df_stat_test)

print("mean of setting a data for duration is statically different ")
summary(one.way_settings)

TukeyHSD(one.way_settings)

```


They do but are not a constent if we look at bar graph
```{r}
#one.way_plus_sys <- aov(Duration.s. ~ node_numb + system_type , data = df_stat_test)

#summary(one.way_plus_sys)

#TukeyHSD(one.way_plus_sys)

```
The mean duration time of System Type( either Hadoop or spark is statistically significant at a significance of 0.05) but our setting changes do not make a statically significant change to the mean 


If we now just a T-Test between each of the system types we can conclude spark is faster then Hadoop on K-means 


```{r}


t.test(Duration.s. ~ system_type , data = df_stat_test)



```


```{r}

t.test(Duration.s. ~ settings, data = df_stat_test)

```

Summary statics about mean deuration for each type of treatment

```{r}
df_sum_stat <- subset(df_bar, select = -c(Date , Time))

print(summary(df_sum_stat))

aggregate(df_sum_stat$Duration.s., list(df_sum_stat$Type), median)

aggregate(df_sum_stat$Duration.s., list(df_sum_stat$node_numb, df_sum_stat$Type, df_sum_stat$settings ), median)

#aggregate(df_sum_stat$Duration.s., list(df_sum_stat$node_numb, df_sum_stat$Type, df_sum_stat$settings ), count)

#aggregate(hibench_Kmeans_15nodes_article_settings$Duration.s., list(hibench_Kmeans_15nodes_article_settings$Type), median)


```


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
